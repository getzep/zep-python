{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a LangGraph Agent\n",
    "\n",
    "The following example demonstrates building an agent using LangGraph. Zep is used to personalize agent responses based on information learned from prior conversations. \n",
    "\n",
    "The agent implements:\n",
    "- persistance of new chat turns to Zep and recall of relevant Facts using the most recent messages.\n",
    "- an in-memory MemorySaver to maintain agent state. We use this to add recent chat history to the agent prompt. As an alternative, you could use Zep for this. \n",
    "\n",
    "**IMPRTANT**: You should consider truncating MemorySaver's chat history as by default LangGraph state grows unbounded. We've included this in our example below. See the LangGraph documentation for insight.\n",
    "\n",
    "## Install dependencies\n",
    "```shell\n",
    "pip install zep-cloud langchain-openai langgraph ipywidgets\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "from contextlib import suppress\n",
    "from typing import Annotated\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logging():\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.ERROR)\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setLevel(logging.ERROR)\n",
    "    formatter = logging.Formatter('%(name)s - %(levelname)s - %(message)s')\n",
    "    console_handler.setFormatter(formatter)\n",
    "    logger.addHandler(console_handler)\n",
    "    return logger\n",
    "\n",
    "\n",
    "logger = setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangSmith integration (Optional)\n",
    "\n",
    "If you'd like to trace your agent using LangSmith, ensure that you have a `LANGSMITH_API_KEY` set in your environment.\n",
    "\n",
    "Then set `os.environ['LANGCHAIN_TRACING_V2'] = 'false'` to `true`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LANGCHAIN_TRACING_V2'] = 'false'\n",
    "os.environ['LANGCHAIN_PROJECT'] = 'Zep LangGraph Tutorial'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Zep\n",
    "\n",
    "Ensure that you've configured the following API key in your environment. We're using Zep's Async client here, but we could also use the non-async equivalent.\n",
    "\n",
    "```bash\n",
    "ZEP_API_KEY=\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zep_cloud.client import AsyncZep\n",
    "from zep_cloud import Message\n",
    "\n",
    "zep = AsyncZep(api_key=os.environ.get('ZEP_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, SystemMessage, trim_messages\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, StateGraph, add_messages\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Zep's Search as a Tool\n",
    "This is an example of a simple Tool that searches Zep for facts related to a user, irrespective which chat session. We also include relevant facts from the current session in the Agent's prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    user_name: str\n",
    "    session_id: str\n",
    "\n",
    "\n",
    "@tool\n",
    "async def search_facts(state: State, query: str, limit: int = 5):\n",
    "    \"\"\"Search for facts in all conversations had with a user.\n",
    "    \n",
    "    Args:\n",
    "        state (State): The Agent's state.\n",
    "        query (str): The search query.\n",
    "        limit (int): The number of results to return. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of facts that match the search query.\n",
    "    \"\"\"\n",
    "    return await zep.memory.search_sessions(user_id=state['user_name'], text=query, limit=limit, search_scope=\"facts\")\n",
    "\n",
    "\n",
    "tools = [search_facts]\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0).bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot Function Explanation\n",
    "\n",
    "The chatbot uses Zep to provide context-aware responses. Here's how it works:\n",
    "\n",
    "1. **Context Retrieval**: It retrieves relevant facts for the user's current conversation (session). Zep uses the most recent messages to determine what facts to retrieve.\n",
    "\n",
    "2. **System Message**: It constructs a system message incorporating the facts retrieved in 1., setting the context for the AI's response.\n",
    "\n",
    "3. **Message Persistence**: After generating a response, it asynchronously adds the user and assistant messages to Zep. New Facts are created and existing Facts updated using this new information.\n",
    "\n",
    "4. **Messages in State**: We use LangGraph state to store the most recent messages and add these to the Agent prompt. We limit the message list to the most recent 3 messages for demonstration purposes. You may also use Zep's chat history for this purpose. \n",
    "\n",
    "This approach enables the chatbot to maintain context across interactions and provide personalized responses based on the user's history and preferences stored in Zep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chatbot(state: State):\n",
    "    memory = await zep.memory.get(state[\"session_id\"])\n",
    "    facts_string = \"\"\n",
    "    if memory.relevant_facts:\n",
    "        facts_string = \"\\n\".join([f.fact for f in memory.relevant_facts])\n",
    "\n",
    "    system_message = SystemMessage(\n",
    "        content=f\"\"\"You are a compassionate mental health bot and caregiver. Review information about the user and their prior conversation below and respond accordingly.\n",
    "        Keep responses empathetic and supportive. And remember, always prioritize the user's well-being and mental health.\n",
    "\n",
    "        Facts about the user and their conversation:\n",
    "        {facts_string or 'No facts about the user and their conversation'}\"\"\"\n",
    "    )\n",
    "\n",
    "    messages = [system_message] + state[\"messages\"]\n",
    "\n",
    "    response = await llm.ainvoke(messages)\n",
    "\n",
    "    # Add the new chat turn to the Zep graph\n",
    "    messages_to_save = [\n",
    "        Message(\n",
    "            role_type=\"user\",\n",
    "            role=state[\"user_name\"],\n",
    "            content=state[\"messages\"][-1].content,\n",
    "        ),\n",
    "        Message(role_type=\"assistant\", content=response.content),\n",
    "    ]\n",
    "\n",
    "    await zep.memory.add(\n",
    "        session_id=state[\"session_id\"],\n",
    "        messages=messages_to_save,\n",
    "    )\n",
    "\n",
    "    # Truncate the chat history to keep the state from growing unbounded\n",
    "    # In this example, we going to keep the state small for demonstration purposes\n",
    "    # We'll use Zep's Facts to maintain conversation context\n",
    "    state[\"messages\"] = trim_messages(\n",
    "        state[\"messages\"],\n",
    "        strategy=\"last\",\n",
    "        token_counter=len,\n",
    "        max_tokens=3,\n",
    "        start_on=\"human\",\n",
    "        end_on=(\"human\", \"tool\"),\n",
    "        include_system=True,\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Messages in state: {state['messages']}\")\n",
    "\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Agent\n",
    "\n",
    "This section sets up the Agent's LangGraph graph:\n",
    "\n",
    "1. **Graph Structure**: It defines a graph with nodes for the agent (chatbot) and tools, connected in a loop.\n",
    "\n",
    "2. **Conditional Logic**: The `should_continue` function determines whether to end the graph execution or continue to the tools node based on the presence of tool calls.\n",
    "\n",
    "3. **Memory Management**: It uses a MemorySaver to maintain conversation state across turns. This is in addition to using Zep for facts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "async def should_continue(state, config):\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if not last_message.tool_calls:\n",
    "        return 'end'\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return 'continue'\n",
    "\n",
    "graph_builder.add_node('agent', chatbot)\n",
    "graph_builder.add_node('tools', tool_node)\n",
    "\n",
    "graph_builder.add_edge(START, 'agent')\n",
    "\n",
    "graph_builder.add_conditional_edges('agent', should_continue, {'continue': 'tools', 'end': END})\n",
    "graph_builder.add_edge('tools', 'agent')\n",
    "\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our LangGraph agent graph is illustrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAERAPYDASIAAhEBAxEB/8QAHQABAAIDAQEBAQAAAAAAAAAAAAYHAwQFCAIBCf/EAFUQAAEDAwICBAUMDQoFBQEAAAEAAgMEBREGEgchExUxQQgUIpTRFhdRU1RVVmGTs9LTIzI0N0JydHWBkZKVsSQzNTZDRVJxpLIYYmODoSdER4Kjw//EABsBAQEAAwEBAQAAAAAAAAAAAAABAgMEBQcG/8QANBEBAAECAQgHBwUBAAAAAAAAAAECEQMEEhMhMVFxkRQzQVNhodEFIzJSgbHwImKSweHx/9oADAMBAAIRAxEAPwD+qaIiAiIgIiICIiAiKLh1XrTLqeqntth5tbLTnZUVvP7Zj+2OL2HDDn5y0tbgv2UUZ2uZtELEO9WXOjt+PGquCmzzHTSNZ/ErU9VVk9+KDzpnpWtR6E07Q5MVkoTISS6WSBskjie0ue4FxPxkra9S1l96KDzZnoWz3Mb/AC/1dT89VVk9+KDzpnpT1VWT34oPOmelfvqWsvvRQebM9Cepay+9FB5sz0J7nx8jU/PVVZPfig86Z6U9VVk9+KDzpnpX76lrL70UHmzPQnqWsvvRQebM9Ce58fI1Pz1VWT34oPOmelfo1VZScC8UGfylnpT1LWX3ooPNmehBpezA5FooM/kzPQnufHyTU36eqhq4xJBKyaM/hxuDh+sLKo5U8PrDJJ01LQMtNYBhtXbP5NKO8ZLMbhn8F2QcnIOSsltuNZbK+K1XeTxh827xS4NjDG1AAyWPA5NlABOBgOALmgYc1smimqL4c38J/NZbc76Ii0IIiICIiAiIgIiICIiAiIgIiICIiAiIgjWvpXyWentsbyx92qoqAuBIIjccy4I5g9E2TBHYcFSKKJkETI42NjjYA1rGDAaB2ADuCjeuh0DbFcDno6G6wPkIGcNkDoM/5DpgSe4AnuUnXRX1VNvHn/yy9gihl641cPdN3Sott215pm13Gndtmo628U8M0RxnDmOeCDgg8x3rSPhC8LB/8l6P/f1L9YudGHWHG+3aT11DpGCwag1HeTRsuNTHZKNkzaOnfI6Nkkhc9p5ua7kwOdhpOMLg6R41X2+8fda6HqNJ3Lqe0eJsp7nEyARwdJFK90k5M+4tkLWiPYwnl5Qb2qHccbXdeLE9uvfC6xQXi7spWx2fiNYtRU8UdHIJyJYZ2h2Z4BtyWASAlzhtaRkymm05rXSHHXVt1obCLvZdXUdujN5gq4YxbJqeOWNxkhkcHPad7XDZu7CCg7unuPluvOt6DS9fpjU+mKy5mcWypvtvbBBXuiaXvbGWvc4ODA52HtaSAcKJ3vwp21/DvWuoNJ6N1HcTp+muLTW1NLAyjjqqUuYWvJqGuewFokJjz5GRkP8AJVa8PuB+srRrLhferhw8bDfbBcpXak1RUXmCpq7sZaeaF1QwlxcYg6TeWPLXNGGtYeatTQnCe/R+DnrHRVyp2Wu73l9/jiEkrZGtbV1FSYXuLC4YLZWOx2jOCARhBPuEOtq/iDoK1Xq52O4WGsngiL4bg2FpmJiY4yxiKSQdG4uO3cQ7kctHfM1UHD3iZDoLQVhtvE5tr4a3GlpYqKCO83yj213QxsbJLCRJzaCRyOCNwyBld/8A4hOFmCfXK0hgcs9fUv1iCwFxNZ2yS66arWU5Da6FnjFJI7P2OePy43cueNwGR3jI71g0pxH0nruSpj01qiy6hfTBrp22q4Q1RiDs7S4RuO3ODjPbgro6iujLJYLlcJASylp5JiGjJO1pOAO8nGAO9bMKaorpmnbdY2stmucd7s9DcYQRDVwR1DAe5r2hw/8ABW4uTpG1PsWlLLbZMdJR0UFO7Hssja0/wXWUrimK5inZckREWCCIiAiIgIiICIiAiIgIiICIiAiIg1rjb6e7W+poquITUtTG6KWN3Y5rhgj9RXFtV5ktE8NnvUwbVHyKStecMrW9gGTyE2Ptmd/NzeWQ2RrXr7fS3WjlpK2miq6WVu2SCdgex49gtPIrbRXERm1bPt+eaxL9koaaV5e+nie49rnMBJXz1ZRj/wBpB8mPQuD6gqaDlQ3W8W2PniKCue9jc+w2TcAPiGB8S+fURP8ACm/fLxfVLPMw52V+X/S0b0mjiZCwMjY1jB2NaMBfai3qIn+FN++Xi+qT1ET/AApv3y8X1SaPD+fylbRvSlFVWnbddLpxA1fZp9U3nxO1tojT7JYt/wBljc5+49Hz5tGOQUs9RE/wpv3y8X1SaPD+fyktG9JJqaGox0sTJcdm9oOFj6to/csHyY9Cj/qIn+FN++Xi+qX63RM4IPqovxx3GeLn/wDmmjw/n8pLRvSERU1BHJKGRU7Gt3PeAGgAd5PsKOGVuuqmnMGH6dp5WzGfnitkYQ5mzuMTXAO3dji0Y5ZJyR8PrW+RklwfWXtzCC1tzqXzRgg5B6InZkHnnbkcufJSZM6jD10Ted+y3D81JqjYIiLnQREQEREBERAREQEREBERAREQEREBERAREQEREBERBXujSPXf4jYPPo7Zn5GT41YSr3Rv33+I3Z/N2zsxn+Zk/T+tWEgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgrzRg/8AWDiPzB+x2zkO0fYZFYarzRmPXh4j+z0ds7v+jIrDQEREBERAREQEREBERAREQEREBERAREQEREBERAREQERfL3tjY573BrWjJcTgAIPpFCjq++XYCos1soRbX84Z7hUyMkmb/jEbYztae0ZOSDzDexfPXmsPcNj86m+rXZ0XE7bR9YWybrQv9bWW2w3Kst9D1pX09NJLT0PS9F4xI1pLI9+Dt3EAZwcZzgqL9eaw9w2Pzqb6tOvNYe4bH51N9WnRa98c4LPInAjw6qviR4QVTZKHhvPFWamqaWnmBurSaCOBjhNK4dAN+1pc7bkfa4zzyveS808PPB/m4bcZNY8RbbQWZ1z1CBindPKI6QuO6Ys8j+0eA7uxzA5FW/15rD3DY/Opvq06LXvjnBZN0UI681h7hsfnU31adeaw9w2Pzqb6tOi1745wWTdFFrTquuZcIKK+UVPSPqXbKapo53SxPeATsdua0scQDjtBweYJAMpXPiYdWHNqi1hERa0EREBERAREQEREBERAREQEREBERAREQFyNXEt0neiDgiinIP8A23Lrrkaw/qle/wAhn+bctuF1lPGFja4engBYLaAAAKaLkPxAugtDT/8AQNt/Jov9gW+vQr+KSdoiIsUEREBFo0t8t9bda62U9bBPcKFsb6qmjkDpIBICY94HNu4NcRntAW8g4OrDg2MjtF3pOf8A3AFYKr7Vv9x/nej+dCsFaso+Cj6r2CIi4UEREBERAREQEREBERAREQEREBERAREQFyNYf1Svf5DP825ddcjWH9Ur3+Qz/NuW3C6ynjCxtcTT/wDQNt/Jov8AYFtVVTFRU01RM7ZDEwyPce5oGSf1LV0//QNt/Jov9gW85oe0tcAWkYIPevQr+KSdryPw+1VqaDidw2vtBU6jGj9Zz1kTGak1D46+si8VlnhlFL0eyl5xtI2PPknBaMrn8L77qLU+quH1d1/q27avhuNfLrKxz1FRHb6IRxztDOjGImBshjbG1pIfnJDscvQFn8HLh3p+52+4UGnRT1duqRV0Mgrah3ib+eWwgyERRnccxsAY7sLTgKtNG+Drq/T2vbRcYKi0aZtVBcDVTOsl6usxrYPKPi5o55DBE124ZILsY8kBc+bMIivCdnF3ibYdNcQLfcQ2puNYyrqJJ9VzOojTiYiam6t8U6NmGBzBiTeHAOLycr9u1x1BQ6A4g6+j1fqI3bT2uaqloaR1yk8SbStubIzTvg+1kYWSOA35LRtDS0ABX7b+AegrTq71S0VgbS3Xxl1aDFVTtpxUOBDpRTh/RB5ycuDM8+1dGp4SaTq9NXrT8tq32i8177pXU/jMo6apfMJnP3B+5uZGh2GkDljGOSubIq/h1oukd4U/Fa5m4XgT0bbVOyAXWoEDzLTzAiSLfse0c9jXAhn4OFf6idz4VaXu+t6TV9RbXDUVKxkTK2Cqmh3taSWtkYx4bKAScbw7GVLFnEWHB1b/AHH+d6P50KwVX2rf7j/O9H86FYKwyj4KPr/S9giIuFBERAREQEREBERAREQEREBERAREQEREBcjWH9Ur3+Qz/NuXXWKqpo6ymmp5m74pWGN7fZaRghZ0Tm1RVuWES0//AEDbfyaL/YFvqMuqL1pM0dn6kqb8G7aeCqt8ke4sDHFrpmvc3o+UbhuJ2ucAAQXBq2+tr/8AA25+dUf169aaYqmZiqLcY9Vs7aLidbX/AOBtz86o/r062v8A8Dbn51R/XrHR/uj+VPqWdtFXVg4z0uqNaag0la7JW1mobAIjcaJlTS7oBIMt5mbDvYO0naeRweSlXW1/+Btz86o/r00f7o/lT6lnbRcTra//AANufnVH9enW1/8Agbc/OqP69NH+6P5U+pZ8at/uP870fzoVgquoDcLtqa3Q3i0VFkt9NiujlmkZI2aZrmsbG57HFrCHSNcGk5eftftXKxVy5RMWpoib2SdwiIuJBERAREQEREBERAREQEREBERAREQEREBcm5XaY1DaC2xdNVydIx1TtEkNE4R7mumG5pOS6PDAdxD8jABcMV1rKy4Ty2u2Pmo5nQiR116BskMP2QNLG7iA6UtEmOTmsLQXggta/oW61UdojmZR00dM2aaSolEbcb5HuLnvPskk9qDDarJT2p004Amr6kRmrrHNAkqHMYGBzsAAch2AADJwBkrooiAtS7mubaa02tlPJcxA80rKtzmwul2nYHloJDd2MkAnGcArbRB/Pfwb/Bj4x8PPChuup67UenK+ennY7Ue2sqSayGr3SP2ZgG54I3AO2jc1vPHNf0IVd6Mx68PEfBOejtmRj/oyKxEBERBrXK2Ud6t1Vb7hSQV1BVROhnpamMSRTRuGHMe1wIc0gkEHkQVywy52Wv8AJdJdbbU1A8g7WyW+Pou49srC9o5HLwZDzLQA3uog1LVdaK+22luNuqoa6gqoxLBU07w+ORhGQ5pHIgrbXCutsraB9RcrKTLViAsFrlm6Oknd0m8uPkkskOZBvHI7/LDtrdu/bbzR3eStjpZukkoqg0tTGWlropA1rtrgQCMtcxwPYWuaRkEFBvIiICIiAiIgIiICIiAtPraj90MW4qy1HqO16RslZeL1XQW210jOknqqh+1jG9nM/GSAB2kkAc0Fg9bUfuhidbUfuhipS2cctEXXT13vkd68Wtdpax9bPX0k9J0QfnYdsrGuduIw3aDk8hkr4ouPOhK/T94vTL8IaCzmIXA1VLPTy0okIEbnxSMbI1rieTtuDgnOAUF3dbUfuhidbUfuhio6LjtpC4WrUFXba6aunstEa+ejNFURTPhwdr42OjDpGOLSA9gc341Ev+JOhunAyl1rSvZZLhUR0seLva699HBUyta8tLo4Q6SPG4CVg2E7fK5gIPT3W1H7oYubcb46epjpLfVRU72ujknqJ4HPZ0W7ymM5tBeQCAckM5FwPJrqg1Nx80LpG8XK1XO9mCvtj4218bKOolFIHsZI18rmRuaxha9p3uIbnIzkHEot2rrPcNQ1lgpK0T3SjpYa2aFrXENhlLxG8PxtduMb+wk8ufaEE/tRtFkoIqKhMdPTRZ2saSeZJLnEnm5xJJLjkkkkkklbXW1H7e1UlVceNDUmmrJfn3svt17a59uEFHPLPUtb9s5sDYzLhveduBkZxkKU6W1VaNa2SmvFjr4rlbajPR1EJ5EgkOBB5ggggggEEEEILQREQEREFfaJcZeK/Eh4ztjfboM88bhTbz/4kb+tWCq+4PP61i1dqHkY71qCqkhdtA3RU4ZRMdy7Q4Um8HvDwe9WCgIiICIiAufc7QK+ekqY55aarpHOfE9j3BjssLS2RoI3s552nva0jBAK6CIORbb451NHFdGRUN0ZGw1MEMjpYmvI59HIWt3tznBLWnGMtaeS2+tqP3QxR6/t3XOXmRjaeX+QVZWzjxoW7aljsNNf4n3KSodSxHoZRTzTAkGOOoLBE9+QRta4nIIwgu7raj90MTraj90MVHUvhAaBrbzDa4b+HVUtc+1hxpJxC2rbI6MwPlMexkhc0gNc4FwILchwJ4nGvwitOcLbJqWmgudPNq2222SrhoH0088TJSwmFs7oxtjDzjAc9pIIx2hB6PiuNNPIGRzNc89gC2VBdD1slzhtNZKGtlqKdsrgwYaC6PJx8XNTpAREQEREBecvCK01ddQ6KtdRabdJepLNfKC8VFpiI310EEwfJE0OIBdjygD2loC9GqI9S1vtB/aHpQeeOJl9r+LOjaSts2kNStGnL7bLzNbrrbXUctxiim3SxQskIL3NaN2CACQ0AuUD4t2i/wDFY8QNUWjSl9orc7TlFZaemr7dJDWXCcV4nc5lOR0m2NhxkgZ3OxkDK9h9S1vtB/aHpTqWt9oP7Q9KCktVaYud149y1FPRT+JVGhq23+PGJ3QCd1VEWRukxjdjcQ3OcZKryobedQeB7No9mlNQ0morJa7Zbp6KptkrTPLFLE15gIBEzQIi7czIwQV6w6lrfaD+0PSnUtb7Qf2h6UHnW46ZudVWeEg4WmrkZdqKKKgIpnkVpFqEZbFy+yYfluG58rl2rR0Y+8cNNaUV1uGmL9coLtoy0UUXV1A+Z0dXT9L0kE3tLj0rfKk2t7cuGCvRNoHW/jjKRzKl9HUvpagMIBilbgljh3HDmn4wQewrf6lrfaD+0PSg8PaK4fXnS1t4aX3UVg1obQzShs9TTaakrKe4W+qFU+UGWGBzJSx7XAHkcFjSQORXp/hBpy06d0cx1ntd3s8NwqZa+amvs0ktb0r3eU+UyPe7c7Adguzz54OVYXUtb7Qf2h6V+iy1uf5g/tD0oJaiIgKI8UtR1en9Izx2l7G6hub22y0h4Lh43KCGOIHa1gDpXf8AJG7mMZUuVd6bxxA19Vamcd9jsRltlnBHkzVGdtXVD2QCPF2HkRsnIy2QFBL9K6bo9HaZtVitzXNobbSx0kAecu2MaGguPeTjJPecrqoiAiIgIiICIiCEa1o5bgy50sExppp4HRMmb2xuczAd+gnK8lcHeHlvit2j9Jao0pxBiv8AZJ4emfLX10ljjmpjvjqGOM3QFjnMaWtaMguA2gAr2Xd7ZU1NfJJHEXMIGDkewtLqWt9oP7Q9KDylU6Qvj/B4v9Cyx3HrN+uHV0NL4pJ05i68ZIJWsxu29Hl+7GNvPsWjrCK+aS0nxz0jNo3UV3uep6i419sudptr6unqoqiBrY2Okb9o6PaWbHYOGjaHZ5+tIrbVmrnpxTzb2NbIXOadhDsgBruwkbTkA5GRnGRnP1LW+0H9oelBzuHkMlPb7FFKx0crKSNrmPGHNIiwQR3FT9R202yqp7hFJJEWsGcnI9gqRICIiAiIgIiICIiAiIgjtTXCx6vgFVcttLemtpqSh8T5CqjZJI9xmb3viaBtf7T5J5kGRLn363zXS0z09NW1FvqDtfHU0u3pGua4OHJw2kHGCDyIJHeuZaeIFjudZa7bLXQ2vUFxohXxWC4yshuLYjnJdTl27ySHAkZblp5lBI0REBEXM1LqKi0nY6u7XB7m01O0EtYMvkcSGsjY38J73FrWtHMucAOZQRviLeayqkotIWSqkpL5emv31kH29uo246ap+J3Nscfb9kkYcFrH4ldotNJYbVR223wNpaGkhbBBCzOGMaAGgZ9gBR7QGna2gjrb5e2BupbyWS1kYkEjaSNuehpGOAwWRBzuY5Oe+V/LfgS1AREQEREBERAREQEREEdEGziCZhS3AiS1hjqrpP5GNspIZs9s8snP+EY7lIlHHwN9cSGbxe57xans8YDv5CB0zDtI9t7wf8IcpGgIiICIiAiIgIiICIiAuHdtcadsNU6muN8t9DUtALoZ6ljHtyMjLScjPcsur7nLZNJ3q4wHE1JRT1DCRnDmRucOXfzC4ditsFqtcEELfwQ98h5uleebnuJ5uc4kkk5JJK68LCpqpz69mzUvjLkcQNT6S11o26WKHiFHp2asjDY7pZ7o2Cqp3Bwc1zHtcCOYAIyMgkd68Q+C9wxuHBjwwbhctU6jor5bZqCsnj1R48Jo6uSRzfKkeXEtlJLsh/MnJ5ggn+gqLfosHdPOPRdTD66mjvhRafPI/SnrqaO+FFp88j9KzImiwd0849DUw+upo74UWnzyP0qCx8QdNa1126uuN+t1Np/T8xjt1NUVDGmtrNo3VZaTnZGC6OPOMuMr8ECF6sBE0WDunnHoame06407fqptNbr5b66pcCWwwVLHvdgZOGg5OO9dxQ2+22G62ueCZv4JeyQcnRvHNr2kc2uaQCCCCCAu3pC5y3rSdluM53TVdFBUPOMZc+Nrjy7uZWjFwqaac+jZs1p4w66Ii5EEREBERARaV2vdvsNKam511Nb6cHHS1UrY259jJI5qLycZ9GRnHXcb+eMxwyvH6w0hb8PAxcWL4dEzwiZW0ymqKD+vVoz35/0s30E9erRnvz/pZvoLb0PKe6q5SWlEZPCE4UeuRC71xdPbxa3x9ONR0nigPTM8gs6T+d7wf8IIVzL+btx8HTR9V4ZrNTiqiPDaWTryVvi8m0VWcmm2bM7TJ5fZjacZyF7q9erRnvz/AKWb6CdDynuquUlpThFB/Xq0Z78/6Wb6C+mcaNGPOOu2M+OSCVg/WWgJ0PKe6q5SWlNkWjaL7bdQU3jFsr6a4QZwZKWVsjQfYJB5H4lvLkmJpm0xaUERFAREQEREEc4kfe71T+aqr5lyxUv3LD+IP4LLxI+93qn81VXzLlipfuWH8QfwXo4XUxxn7QvYyosNa+eKjnfSwsqKlsbjFFJJ0bXvx5LS7B2gnAzg49grzvwq4+aot/Ab1Y64tMdfK+pdS251vrWy1N0qZK2WBkHRdFGyLDtjAdzstBcQMYSZiEejkVKVnhISaMbqKn19paXTV1tVqZeYaWgrm3BldA6UQBscgYzEnTOjYWuA5yNIJByvi58ZNQGmvmndT6Wk0VfarTtbdLTNS3RtYyUQsxI3pGsYY5oy+N2Bkc8hxwmdAu5F5+svHC8ad0bwfsdFZTqrU2pNNQVxmud2bRtmMdPCZPs0jXmWZxkzt7TzJI7VflLJJLTRPmi6CVzA58W4O2OI5tyORx2ZSJuFV9yzfiH+Cy8N/vd6W/NVL8y1Yqr7lm/EP8Fl4b/e70t+aqX5lqYvUzxj7Sy7EjREXnMRERAUV4ha4Zoq1xuijZU3OqJZS073YBIxue7v2tyM47cgcs5UqXnzibcn3TiLdWPJMduZDRxjuGY2yuI/zMoB/EHsL1fZuS05VlGbXsiLz+cZVHa2We7XB1fcZ319e7+3nOdo9hg7GN/5W4H6ea/ERfQoiKYiI2MJm4i+ZpmU8L5ZHBkbGlznOOAAOZJVL2fwnLVdrrbGimoG2m51cdHTSxXmCWuBkdtjfLSDymNJIz5RLQckDnjViY2HhTEVza4upFU8PG+vNMbpPpYwadivLrNUV/WDXSMeKk07ZWxbPKZu25y4EEnAcBk87irxTvVTpfXsGl7LPNR2alnpaq/MrxTOp6gRbndC3G55j3Ak5bzyBkhaqsqw4pmqJ8p/PqLpRaNhkfNYrdJI5z5H00bnOcckktGSSt5dUTeLo/aR81tr2V9BPJQV7PtaiA4cficOx7eQ8lwIV78Otdt1pbZW1EbKe7Um1tVBGfIIOdsjM89rtrsA8wWuGTjJodd/hzcX2riFZix2GVvS0Uox2tMbpG/qdG39oryfaeSUZRgVV2/VTF4nh2M4m+p6HREXz4EREBERBHOJH3u9U/mqq+ZcsVL9yw/iD+Cy8SPvd6p/NVV8y5YqX7lh/EH8F6OF1McZ+0L2Mq870HALWUXDaq0LNcbHFQWm49babu8RmfUCoZWmriFTCWhoaCSwljiSDkc16IRJi6PPWpPB+1XxbqNR3XW9ys9qu1TZGWa1QWEy1EFIW1LKrxiR0rWF7jNDD5IAAawjJJyuxDwm1nr3Vjb5xArLHSGhslbaLfS6edNK3fVBjZ6h7pWtIO2NobGAQOflFXaimbA87X3gzxBvHBXT2gauh0LeW0FtNskqbgaoGExsbHTVUBDCWytY3c4cvKPkvA7b00paKjT+lrPa6yvkulXRUcNNNXTfb1L2MDXSO5nm4gk/5rqorEWGKq+5ZvxD/BZeG/3u9Lfmql+ZasVV9yzfiH+Cy8N/vd6W/NVL8y1MXqZ4x9pZdiRoiLzmIiIgLz5xOtj7XxFur3AiO4sirI3dxIjbC4D/AC6NpP449leg1F9f6Ii1pa2MZI2muNMS+lqXN3BpONzXd+1wAB/yB7QF6vs3Kqclx86vZMWn84wrztdbpBZbfNW1ImMEIy4U8Ek7+3HJkbXOd29wKjA4t6fP9lfP06duA/8A4KaXCGey3E2+5wPt9cOyGbkJB/ijd2Pb8bc+wcHkvlfvpzqoiqiYtP1/tha21DRxF09qA9V9DeT47/JsS2KuiZ5fk83uhDWjn2kgDvK4fDzResNFRWqwzv0/XadtuYo68slFdJA0Ho2lmNjXDyQXbjkN7MnKs5FjopqqiqqdcbtXqip5+E13k4ZXPToqaLx2pv5ujJC9/RiI3BtTgnZndsGMYxu78c1oak4WayZb9dWSwVVklsWqH1FTuuTpmVFLNOwNkaNjXNc0kZBOC3J5OxzudFrnJsOYt4W+mv1VCoeIlm09BFa6pl3dU0TG08rqexV0sZc0AHa9sJa4ZHIg4KyO4tafYcGK+dgPLT1wPb/2FMUW3NxI1RMcv9RpWa709+tsNdSCdsEudoqaaSnk5Eg5jka1w5g9oGRzHIhS3hxbX3XiHZg0ZjoelrZTnsAjdG0fpdID/wDU+wuBRRT3avbQW6nkuFc7+wgGdvxvPYxvxuIH6VfPDzQrNF22QzSMqLrV7XVVRGMN5Z2xtzz2t3OxnmSXHlnA832lldOT4E0TP6qotbjtlnEW1pYiIvn4IiICIiDk6utkl70perdCMzVdFNTsBOPKfG5o593MrhWK5wXW2wywuw5rQyWJ3J8TxycxzTza4EEEEdyma4t20Vp6/wBQai52K23Cc4BlqqSORxxyHMgnkuvCxaaacyvZt1L4S1kWH1rNGfBKyfu+L6KetZoz4JWT93xfRW7S4O+eUeq6mZFh9azRnwSsn7vi+inrWaM+CVk/d8X0U0uDvnlHqamZFh9azRnwSsn7vi+inrWaM+CVk/d8X0U0uDvnlHqamrfbnBarbNLM7ynNLI4m83yvPJrGtHNziSAAB3ru6Rtktk0pZbdMMTUlFBTvAOfKZG1p59/MLHadFaesFQKi2WK22+cZAlpaSONwzyPMAHmu0tOLi01U5lGzbrTwgREXIgiIgIiINS6WihvdI6luNFT19K7mYaqJsjD+hwIUZk4P6NkOTYKZvfhhcwfqBAUxRbqMfFwotRVMcJmFvMIX6zWjPeKH5ST6Ses1oz3ih+Uk+kpoi29LynvKucl53oX6zWjPeKH5ST6Ses1oz3ih+Uk+kpoidLynvKucl53oX6zWjPeKH5ST6S+mcHtGxnPUFO74nue4fqJwpkidLyjvKucl53tK1Wa32KlFNbaGnoKcHPRU0TY259nAAW6iLlmZqm8oIiKAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIg//Z",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with suppress(Exception):\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Agent\n",
    "\n",
    "We generate a unique user name and thread id (session id) and add these to Zep, associating the Session with the new User."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_name = 'Daniel_' + uuid.uuid4().hex[:4]\n",
    "thread_id = uuid.uuid4().hex\n",
    "\n",
    "await zep.user.add(user_id=user_name)\n",
    "await zep.memory.add_session(session_id=thread_id, user_id=user_name)\n",
    "\n",
    "def extract_messages(result):\n",
    "    output = \"\"\n",
    "    for message in result['messages']:\n",
    "        if isinstance(message, AIMessage):\n",
    "            role = \"assistant\"\n",
    "        else:\n",
    "            role = result['user_name']\n",
    "        output += f\"{role}: {message.content}\\n\"\n",
    "    return output.strip()\n",
    "\n",
    "\n",
    "\n",
    "async def graph_invoke(message: str, user_name: str, thread_id: str, ai_response_only: bool = True):\n",
    "    r =  await graph.ainvoke(\n",
    "        {\n",
    "            'messages': [\n",
    "                {\n",
    "                    'role': 'user',\n",
    "                    'content': message,\n",
    "                }\n",
    "            ],\n",
    "            'user_name': user_name,\n",
    "            'session_id': thread_id,\n",
    "        },\n",
    "        config={'configurable': {'thread_id': thread_id}},\n",
    "    )\n",
    "\n",
    "    if ai_response_only:\n",
    "        return r['messages'][-1].content\n",
    "    else:\n",
    "        return extract_messages(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How are you feeling today? I'm here to listen and support you.\n"
     ]
    }
   ],
   "source": [
    "r = await graph_invoke(\n",
    "    \"Hi there?\",\n",
    "    user_name,\n",
    "    thread_id,\n",
    ")\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry to hear that you've been feeling stressed. Work can be a significant source of pressure, and it sounds like your dog might be adding to that stress as well. If you feel comfortable sharing, what specifically has been causing you stress at work and with your dog? I'm here to help you through it.\n"
     ]
    }
   ],
   "source": [
    "r = await graph_invoke(\n",
    "    \"I'm fine. But have been a bit stressful lately. Mostly work related. But also my dog.\",\n",
    "    user_name,\n",
    "    thread_id,\n",
    ")\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m really sorry to hear that your dog is sick. It’s completely understandable to feel worried about her; our pets are like family. Have you been able to take her to the vet? Sometimes getting a professional opinion can help ease some of that worry. I'm here to support you through this.\n"
     ]
    }
   ],
   "source": [
    "r = await graph_invoke(\n",
    "    \"She's sick. I'm worried about her.\",\n",
    "    user_name,\n",
    "    thread_id,\n",
    ")\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing All Conversation Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fact: Daniel's dog is also contributing to his stress.\n",
      "Fact: Daniel's stress is mostly work-related.\n",
      "Fact: Daniel has been feeling stressed lately.\n"
     ]
    }
   ],
   "source": [
    "facts = await zep.memory.get_session_facts(session_id=thread_id)\n",
    "\n",
    "print(\"\\n\".join([f\"Fact: {fact.fact}\" for fact in facts.facts]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That sounds really frustrating, especially on top of everything else you're dealing with. It's tough when our pets do things that add to our stress, especially when it involves something valuable. It’s okay to feel upset about it. How are you managing with everything?\n"
     ]
    }
   ],
   "source": [
    "r = await graph_invoke(\n",
    "    \"She ate my shoes which were expensive.\",\n",
    "    user_name,\n",
    "    thread_id,\n",
    ")\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now test whether the Agent is correctly grounded with facts from the prior conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We were discussing the stress you've been feeling lately, particularly related to work and your dog's health. You mentioned that your dog has been sick and also chewed up your expensive shoes, which can be really frustrating. If there's something else on your mind or if you'd like to talk about a different topic, I'm here to listen!\n"
     ]
    }
   ],
   "source": [
    "r = await graph_invoke(\n",
    "    \"What are we talking about?\",\n",
    "    user_name,\n",
    "    thread_id,\n",
    ")\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go even further back to determine whether context is kept by referencing a user message that is not currently in the Agent State. Zep will retrieve Facts related to the user's job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You've mentioned that you've been feeling stressed lately, and it seems that your job is a significant part of that stress. If you'd like to share more about what's been going on at work, I'm here to listen and help however I can.\n"
     ]
    }
   ],
   "source": [
    "r = await graph_invoke(\n",
    "    \"What have I said about my job?\",\n",
    "    user_name,\n",
    "    thread_id,\n",
    ")\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
