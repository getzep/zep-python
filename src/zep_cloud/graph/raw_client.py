# This file was auto-generated by Fern from our API Definition.

import typing
from json.decoder import JSONDecodeError

from ..core.api_error import ApiError
from ..core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ..core.http_response import AsyncHttpResponse, HttpResponse
from ..core.jsonable_encoder import jsonable_encoder
from ..core.pydantic_utilities import parse_obj_as
from ..core.request_options import RequestOptions
from ..core.serialization import convert_and_respect_annotation_metadata
from ..errors.bad_request_error import BadRequestError
from ..errors.internal_server_error import InternalServerError
from ..errors.not_found_error import NotFoundError
from ..types.apidata_api_error import ApidataApiError
from ..types.apidata_clone_graph_response import ApidataCloneGraphResponse
from ..types.apidata_edge_type import ApidataEdgeType
from ..types.apidata_entity_type import ApidataEntityType
from ..types.apidata_entity_type_response import ApidataEntityTypeResponse
from ..types.apidata_episode_data import ApidataEpisodeData
from ..types.apidata_fact_rating_instruction import ApidataFactRatingInstruction
from ..types.apidata_graph import ApidataGraph
from ..types.apidata_graph_episode import ApidataGraphEpisode
from ..types.apidata_graph_search_results import ApidataGraphSearchResults
from ..types.apidata_success_response import ApidataSuccessResponse
from ..types.graphiti_add_triple_response import GraphitiAddTripleResponse
from ..types.graphiti_graph_search_scope import GraphitiGraphSearchScope
from ..types.graphiti_reranker import GraphitiReranker
from ..types.graphiti_search_filters import GraphitiSearchFilters
from ..types.models_graph_data_type import ModelsGraphDataType

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class RawGraphClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def list_entity_types(
        self, *, request_options: typing.Optional[RequestOptions] = None
    ) -> HttpResponse[ApidataEntityTypeResponse]:
        """
        Returns all entity types for a project.

        Parameters
        ----------
        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[ApidataEntityTypeResponse]
            The list of entity types.
        """
        _response = self._client_wrapper.httpx_client.request(
            "entity-types",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ApidataEntityTypeResponse,
                    parse_obj_as(
                        type_=ApidataEntityTypeResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 404:
                raise NotFoundError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def set_entity_types_internal(
        self,
        *,
        edge_types: typing.Optional[typing.Sequence[ApidataEdgeType]] = OMIT,
        entity_types: typing.Optional[typing.Sequence[ApidataEntityType]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HttpResponse[ApidataSuccessResponse]:
        """
        Sets the entity types for a project, replacing any existing ones.

        Parameters
        ----------
        edge_types : typing.Optional[typing.Sequence[ApidataEdgeType]]

        entity_types : typing.Optional[typing.Sequence[ApidataEntityType]]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[ApidataSuccessResponse]
            Entity types set successfully
        """
        _response = self._client_wrapper.httpx_client.request(
            "entity-types",
            method="PUT",
            json={
                "edge_types": convert_and_respect_annotation_metadata(
                    object_=edge_types, annotation=typing.Sequence[ApidataEdgeType], direction="write"
                ),
                "entity_types": convert_and_respect_annotation_metadata(
                    object_=entity_types, annotation=typing.Sequence[ApidataEntityType], direction="write"
                ),
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ApidataSuccessResponse,
                    parse_obj_as(
                        type_=ApidataSuccessResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 400:
                raise BadRequestError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def add(
        self,
        *,
        data: str,
        type: ModelsGraphDataType,
        created_at: typing.Optional[str] = OMIT,
        graph_id: typing.Optional[str] = OMIT,
        source_description: typing.Optional[str] = OMIT,
        user_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HttpResponse[ApidataGraphEpisode]:
        """
        Add data to the graph.

        Parameters
        ----------
        data : str

        type : ModelsGraphDataType

        created_at : typing.Optional[str]

        graph_id : typing.Optional[str]
            graph_id is the ID of the graph to which the data will be added. If adding to the user graph, please use user_id field instead.

        source_description : typing.Optional[str]

        user_id : typing.Optional[str]
            User ID is the ID of the user to which the data will be added. If not adding to a user graph, please use graph_id field instead.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[ApidataGraphEpisode]
            Added episode
        """
        _response = self._client_wrapper.httpx_client.request(
            "graph",
            method="POST",
            json={
                "created_at": created_at,
                "data": data,
                "graph_id": graph_id,
                "source_description": source_description,
                "type": type,
                "user_id": user_id,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ApidataGraphEpisode,
                    parse_obj_as(
                        type_=ApidataGraphEpisode,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 400:
                raise BadRequestError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def add_batch(
        self,
        *,
        episodes: typing.Sequence[ApidataEpisodeData],
        graph_id: typing.Optional[str] = OMIT,
        user_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HttpResponse[typing.List[ApidataGraphEpisode]]:
        """
        Add data to the graph in batch mode, processing episodes concurrently. Use only for data that is insensitive to processing order.

        Parameters
        ----------
        episodes : typing.Sequence[ApidataEpisodeData]

        graph_id : typing.Optional[str]
            graph_id is the ID of the graph to which the data will be added. If adding to the user graph, please use user_id field instead.

        user_id : typing.Optional[str]
            User ID is the ID of the user to which the data will be added. If not adding to a user graph, please use graph_id field instead.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[typing.List[ApidataGraphEpisode]]
            Added episodes
        """
        _response = self._client_wrapper.httpx_client.request(
            "graph-batch",
            method="POST",
            json={
                "episodes": convert_and_respect_annotation_metadata(
                    object_=episodes, annotation=typing.Sequence[ApidataEpisodeData], direction="write"
                ),
                "graph_id": graph_id,
                "user_id": user_id,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.List[ApidataGraphEpisode],
                    parse_obj_as(
                        type_=typing.List[ApidataGraphEpisode],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 400:
                raise BadRequestError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def add_fact_triple(
        self,
        *,
        fact: str,
        fact_name: str,
        target_node_name: str,
        created_at: typing.Optional[str] = OMIT,
        expired_at: typing.Optional[str] = OMIT,
        fact_uuid: typing.Optional[str] = OMIT,
        graph_id: typing.Optional[str] = OMIT,
        invalid_at: typing.Optional[str] = OMIT,
        source_node_name: typing.Optional[str] = OMIT,
        source_node_summary: typing.Optional[str] = OMIT,
        source_node_uuid: typing.Optional[str] = OMIT,
        target_node_summary: typing.Optional[str] = OMIT,
        target_node_uuid: typing.Optional[str] = OMIT,
        user_id: typing.Optional[str] = OMIT,
        valid_at: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HttpResponse[GraphitiAddTripleResponse]:
        """
        Add a fact triple for a user or group

        Parameters
        ----------
        fact : str
            The fact relating the two nodes that this edge represents

        fact_name : str
            The name of the edge to add. Should be all caps using snake case (eg RELATES_TO)

        target_node_name : str
            The name of the target node to add

        created_at : typing.Optional[str]
            The timestamp of the message

        expired_at : typing.Optional[str]
            The time (if any) at which the edge expires

        fact_uuid : typing.Optional[str]
            The uuid of the edge to add

        graph_id : typing.Optional[str]

        invalid_at : typing.Optional[str]
            The time (if any) at which the fact stops being true

        source_node_name : typing.Optional[str]
            The name of the source node to add

        source_node_summary : typing.Optional[str]
            The summary of the source node to add

        source_node_uuid : typing.Optional[str]
            The source node uuid

        target_node_summary : typing.Optional[str]
            The summary of the target node to add

        target_node_uuid : typing.Optional[str]
            The target node uuid

        user_id : typing.Optional[str]

        valid_at : typing.Optional[str]
            The time at which the fact becomes true

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[GraphitiAddTripleResponse]
            Resulting triple
        """
        _response = self._client_wrapper.httpx_client.request(
            "graph/add-fact-triple",
            method="POST",
            json={
                "created_at": created_at,
                "expired_at": expired_at,
                "fact": fact,
                "fact_name": fact_name,
                "fact_uuid": fact_uuid,
                "graph_id": graph_id,
                "invalid_at": invalid_at,
                "source_node_name": source_node_name,
                "source_node_summary": source_node_summary,
                "source_node_uuid": source_node_uuid,
                "target_node_name": target_node_name,
                "target_node_summary": target_node_summary,
                "target_node_uuid": target_node_uuid,
                "user_id": user_id,
                "valid_at": valid_at,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    GraphitiAddTripleResponse,
                    parse_obj_as(
                        type_=GraphitiAddTripleResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 400:
                raise BadRequestError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def clone(
        self,
        *,
        source_graph_id: typing.Optional[str] = OMIT,
        source_user_id: typing.Optional[str] = OMIT,
        target_graph_id: typing.Optional[str] = OMIT,
        target_user_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HttpResponse[ApidataCloneGraphResponse]:
        """
        Clone a user or group graph.

        Parameters
        ----------
        source_graph_id : typing.Optional[str]
            source_graph_id is the ID of the graph to be cloned. Required if source_user_id is not provided

        source_user_id : typing.Optional[str]
            user_id of the user whose graph is being cloned. Required if source_graph_id is not provided

        target_graph_id : typing.Optional[str]
            target_graph_id is the ID to be set on the cloned graph. Must not point to an existing graph. Required if target_user_id is not provided.

        target_user_id : typing.Optional[str]
            user_id to be set on the cloned user. Must not point to an existing user. Required if target_graph_id is not provided.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[ApidataCloneGraphResponse]
            Response object containing group_id or user_id pointing to the new graph
        """
        _response = self._client_wrapper.httpx_client.request(
            "graph/clone",
            method="POST",
            json={
                "source_graph_id": source_graph_id,
                "source_user_id": source_user_id,
                "target_graph_id": target_graph_id,
                "target_user_id": target_user_id,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ApidataCloneGraphResponse,
                    parse_obj_as(
                        type_=ApidataCloneGraphResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 400:
                raise BadRequestError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def search(
        self,
        *,
        query: str,
        bfs_origin_node_uuids: typing.Optional[typing.Sequence[str]] = OMIT,
        center_node_uuid: typing.Optional[str] = OMIT,
        graph_id: typing.Optional[str] = OMIT,
        limit: typing.Optional[int] = OMIT,
        min_fact_rating: typing.Optional[float] = OMIT,
        min_score: typing.Optional[float] = OMIT,
        mmr_lambda: typing.Optional[float] = OMIT,
        reranker: typing.Optional[GraphitiReranker] = OMIT,
        scope: typing.Optional[GraphitiGraphSearchScope] = OMIT,
        search_filters: typing.Optional[GraphitiSearchFilters] = OMIT,
        user_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HttpResponse[ApidataGraphSearchResults]:
        """
        Perform a graph search query.

        Parameters
        ----------
        query : str
            The string to search for (required)

        bfs_origin_node_uuids : typing.Optional[typing.Sequence[str]]
            Nodes that are the origins of the BFS searches

        center_node_uuid : typing.Optional[str]
            Node to rerank around for node distance reranking

        graph_id : typing.Optional[str]
            The graph_id to search in. When searching user graph, please use user_id instead.

        limit : typing.Optional[int]
            The maximum number of facts to retrieve. Defaults to 10. Limited to 50.

        min_fact_rating : typing.Optional[float]
            The minimum rating by which to filter relevant facts

        min_score : typing.Optional[float]
            Deprecated

        mmr_lambda : typing.Optional[float]
            weighting for maximal marginal relevance

        reranker : typing.Optional[GraphitiReranker]
            Defaults to RRF

        scope : typing.Optional[GraphitiGraphSearchScope]
            Defaults to Edges. Communities will be added in the future.

        search_filters : typing.Optional[GraphitiSearchFilters]
            Search filters to apply to the search

        user_id : typing.Optional[str]
            The user_id when searching user graph. If not searching user graph, please use graph_id instead.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[ApidataGraphSearchResults]
            Graph search results
        """
        _response = self._client_wrapper.httpx_client.request(
            "graph/search",
            method="POST",
            json={
                "bfs_origin_node_uuids": bfs_origin_node_uuids,
                "center_node_uuid": center_node_uuid,
                "graph_id": graph_id,
                "limit": limit,
                "min_fact_rating": min_fact_rating,
                "min_score": min_score,
                "mmr_lambda": mmr_lambda,
                "query": query,
                "reranker": reranker,
                "scope": scope,
                "search_filters": convert_and_respect_annotation_metadata(
                    object_=search_filters, annotation=GraphitiSearchFilters, direction="write"
                ),
                "user_id": user_id,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ApidataGraphSearchResults,
                    parse_obj_as(
                        type_=ApidataGraphSearchResults,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 400:
                raise BadRequestError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def create(
        self,
        *,
        graph_id: str,
        description: typing.Optional[str] = OMIT,
        fact_rating_instruction: typing.Optional[ApidataFactRatingInstruction] = OMIT,
        name: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> HttpResponse[ApidataGraph]:
        """
        Creates a new graph.

        Parameters
        ----------
        graph_id : str

        description : typing.Optional[str]

        fact_rating_instruction : typing.Optional[ApidataFactRatingInstruction]

        name : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[ApidataGraph]
            The added graph
        """
        _response = self._client_wrapper.httpx_client.request(
            "graphs",
            method="POST",
            json={
                "description": description,
                "fact_rating_instruction": convert_and_respect_annotation_metadata(
                    object_=fact_rating_instruction, annotation=ApidataFactRatingInstruction, direction="write"
                ),
                "graph_id": graph_id,
                "name": name,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ApidataGraph,
                    parse_obj_as(
                        type_=ApidataGraph,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 400:
                raise BadRequestError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def get(
        self, graph_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> HttpResponse[ApidataGraph]:
        """
        Returns a graph.

        Parameters
        ----------
        graph_id : str
            The graph_id of the graph to get.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[ApidataGraph]
            The graph that was retrieved.
        """
        _response = self._client_wrapper.httpx_client.request(
            f"graphs/{jsonable_encoder(graph_id)}",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ApidataGraph,
                    parse_obj_as(
                        type_=ApidataGraph,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 404:
                raise NotFoundError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    def delete(
        self, graph_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> HttpResponse[ApidataSuccessResponse]:
        """
        Deletes a graph. If you would like to delete a user graph, make sure to use user.delete instead.

        Parameters
        ----------
        graph_id : str
            Graph ID

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        HttpResponse[ApidataSuccessResponse]
            Deleted
        """
        _response = self._client_wrapper.httpx_client.request(
            f"graphs/{jsonable_encoder(graph_id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ApidataSuccessResponse,
                    parse_obj_as(
                        type_=ApidataSuccessResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return HttpResponse(response=_response, data=_data)
            if _response.status_code == 400:
                raise BadRequestError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            if _response.status_code == 404:
                raise NotFoundError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)


class AsyncRawGraphClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def list_entity_types(
        self, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[ApidataEntityTypeResponse]:
        """
        Returns all entity types for a project.

        Parameters
        ----------
        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[ApidataEntityTypeResponse]
            The list of entity types.
        """
        _response = await self._client_wrapper.httpx_client.request(
            "entity-types",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ApidataEntityTypeResponse,
                    parse_obj_as(
                        type_=ApidataEntityTypeResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 404:
                raise NotFoundError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def set_entity_types_internal(
        self,
        *,
        edge_types: typing.Optional[typing.Sequence[ApidataEdgeType]] = OMIT,
        entity_types: typing.Optional[typing.Sequence[ApidataEntityType]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncHttpResponse[ApidataSuccessResponse]:
        """
        Sets the entity types for a project, replacing any existing ones.

        Parameters
        ----------
        edge_types : typing.Optional[typing.Sequence[ApidataEdgeType]]

        entity_types : typing.Optional[typing.Sequence[ApidataEntityType]]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[ApidataSuccessResponse]
            Entity types set successfully
        """
        _response = await self._client_wrapper.httpx_client.request(
            "entity-types",
            method="PUT",
            json={
                "edge_types": convert_and_respect_annotation_metadata(
                    object_=edge_types, annotation=typing.Sequence[ApidataEdgeType], direction="write"
                ),
                "entity_types": convert_and_respect_annotation_metadata(
                    object_=entity_types, annotation=typing.Sequence[ApidataEntityType], direction="write"
                ),
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ApidataSuccessResponse,
                    parse_obj_as(
                        type_=ApidataSuccessResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 400:
                raise BadRequestError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def add(
        self,
        *,
        data: str,
        type: ModelsGraphDataType,
        created_at: typing.Optional[str] = OMIT,
        graph_id: typing.Optional[str] = OMIT,
        source_description: typing.Optional[str] = OMIT,
        user_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncHttpResponse[ApidataGraphEpisode]:
        """
        Add data to the graph.

        Parameters
        ----------
        data : str

        type : ModelsGraphDataType

        created_at : typing.Optional[str]

        graph_id : typing.Optional[str]
            graph_id is the ID of the graph to which the data will be added. If adding to the user graph, please use user_id field instead.

        source_description : typing.Optional[str]

        user_id : typing.Optional[str]
            User ID is the ID of the user to which the data will be added. If not adding to a user graph, please use graph_id field instead.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[ApidataGraphEpisode]
            Added episode
        """
        _response = await self._client_wrapper.httpx_client.request(
            "graph",
            method="POST",
            json={
                "created_at": created_at,
                "data": data,
                "graph_id": graph_id,
                "source_description": source_description,
                "type": type,
                "user_id": user_id,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ApidataGraphEpisode,
                    parse_obj_as(
                        type_=ApidataGraphEpisode,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 400:
                raise BadRequestError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def add_batch(
        self,
        *,
        episodes: typing.Sequence[ApidataEpisodeData],
        graph_id: typing.Optional[str] = OMIT,
        user_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncHttpResponse[typing.List[ApidataGraphEpisode]]:
        """
        Add data to the graph in batch mode, processing episodes concurrently. Use only for data that is insensitive to processing order.

        Parameters
        ----------
        episodes : typing.Sequence[ApidataEpisodeData]

        graph_id : typing.Optional[str]
            graph_id is the ID of the graph to which the data will be added. If adding to the user graph, please use user_id field instead.

        user_id : typing.Optional[str]
            User ID is the ID of the user to which the data will be added. If not adding to a user graph, please use graph_id field instead.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[typing.List[ApidataGraphEpisode]]
            Added episodes
        """
        _response = await self._client_wrapper.httpx_client.request(
            "graph-batch",
            method="POST",
            json={
                "episodes": convert_and_respect_annotation_metadata(
                    object_=episodes, annotation=typing.Sequence[ApidataEpisodeData], direction="write"
                ),
                "graph_id": graph_id,
                "user_id": user_id,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    typing.List[ApidataGraphEpisode],
                    parse_obj_as(
                        type_=typing.List[ApidataGraphEpisode],  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 400:
                raise BadRequestError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def add_fact_triple(
        self,
        *,
        fact: str,
        fact_name: str,
        target_node_name: str,
        created_at: typing.Optional[str] = OMIT,
        expired_at: typing.Optional[str] = OMIT,
        fact_uuid: typing.Optional[str] = OMIT,
        graph_id: typing.Optional[str] = OMIT,
        invalid_at: typing.Optional[str] = OMIT,
        source_node_name: typing.Optional[str] = OMIT,
        source_node_summary: typing.Optional[str] = OMIT,
        source_node_uuid: typing.Optional[str] = OMIT,
        target_node_summary: typing.Optional[str] = OMIT,
        target_node_uuid: typing.Optional[str] = OMIT,
        user_id: typing.Optional[str] = OMIT,
        valid_at: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncHttpResponse[GraphitiAddTripleResponse]:
        """
        Add a fact triple for a user or group

        Parameters
        ----------
        fact : str
            The fact relating the two nodes that this edge represents

        fact_name : str
            The name of the edge to add. Should be all caps using snake case (eg RELATES_TO)

        target_node_name : str
            The name of the target node to add

        created_at : typing.Optional[str]
            The timestamp of the message

        expired_at : typing.Optional[str]
            The time (if any) at which the edge expires

        fact_uuid : typing.Optional[str]
            The uuid of the edge to add

        graph_id : typing.Optional[str]

        invalid_at : typing.Optional[str]
            The time (if any) at which the fact stops being true

        source_node_name : typing.Optional[str]
            The name of the source node to add

        source_node_summary : typing.Optional[str]
            The summary of the source node to add

        source_node_uuid : typing.Optional[str]
            The source node uuid

        target_node_summary : typing.Optional[str]
            The summary of the target node to add

        target_node_uuid : typing.Optional[str]
            The target node uuid

        user_id : typing.Optional[str]

        valid_at : typing.Optional[str]
            The time at which the fact becomes true

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[GraphitiAddTripleResponse]
            Resulting triple
        """
        _response = await self._client_wrapper.httpx_client.request(
            "graph/add-fact-triple",
            method="POST",
            json={
                "created_at": created_at,
                "expired_at": expired_at,
                "fact": fact,
                "fact_name": fact_name,
                "fact_uuid": fact_uuid,
                "graph_id": graph_id,
                "invalid_at": invalid_at,
                "source_node_name": source_node_name,
                "source_node_summary": source_node_summary,
                "source_node_uuid": source_node_uuid,
                "target_node_name": target_node_name,
                "target_node_summary": target_node_summary,
                "target_node_uuid": target_node_uuid,
                "user_id": user_id,
                "valid_at": valid_at,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    GraphitiAddTripleResponse,
                    parse_obj_as(
                        type_=GraphitiAddTripleResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 400:
                raise BadRequestError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def clone(
        self,
        *,
        source_graph_id: typing.Optional[str] = OMIT,
        source_user_id: typing.Optional[str] = OMIT,
        target_graph_id: typing.Optional[str] = OMIT,
        target_user_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncHttpResponse[ApidataCloneGraphResponse]:
        """
        Clone a user or group graph.

        Parameters
        ----------
        source_graph_id : typing.Optional[str]
            source_graph_id is the ID of the graph to be cloned. Required if source_user_id is not provided

        source_user_id : typing.Optional[str]
            user_id of the user whose graph is being cloned. Required if source_graph_id is not provided

        target_graph_id : typing.Optional[str]
            target_graph_id is the ID to be set on the cloned graph. Must not point to an existing graph. Required if target_user_id is not provided.

        target_user_id : typing.Optional[str]
            user_id to be set on the cloned user. Must not point to an existing user. Required if target_graph_id is not provided.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[ApidataCloneGraphResponse]
            Response object containing group_id or user_id pointing to the new graph
        """
        _response = await self._client_wrapper.httpx_client.request(
            "graph/clone",
            method="POST",
            json={
                "source_graph_id": source_graph_id,
                "source_user_id": source_user_id,
                "target_graph_id": target_graph_id,
                "target_user_id": target_user_id,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ApidataCloneGraphResponse,
                    parse_obj_as(
                        type_=ApidataCloneGraphResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 400:
                raise BadRequestError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def search(
        self,
        *,
        query: str,
        bfs_origin_node_uuids: typing.Optional[typing.Sequence[str]] = OMIT,
        center_node_uuid: typing.Optional[str] = OMIT,
        graph_id: typing.Optional[str] = OMIT,
        limit: typing.Optional[int] = OMIT,
        min_fact_rating: typing.Optional[float] = OMIT,
        min_score: typing.Optional[float] = OMIT,
        mmr_lambda: typing.Optional[float] = OMIT,
        reranker: typing.Optional[GraphitiReranker] = OMIT,
        scope: typing.Optional[GraphitiGraphSearchScope] = OMIT,
        search_filters: typing.Optional[GraphitiSearchFilters] = OMIT,
        user_id: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncHttpResponse[ApidataGraphSearchResults]:
        """
        Perform a graph search query.

        Parameters
        ----------
        query : str
            The string to search for (required)

        bfs_origin_node_uuids : typing.Optional[typing.Sequence[str]]
            Nodes that are the origins of the BFS searches

        center_node_uuid : typing.Optional[str]
            Node to rerank around for node distance reranking

        graph_id : typing.Optional[str]
            The graph_id to search in. When searching user graph, please use user_id instead.

        limit : typing.Optional[int]
            The maximum number of facts to retrieve. Defaults to 10. Limited to 50.

        min_fact_rating : typing.Optional[float]
            The minimum rating by which to filter relevant facts

        min_score : typing.Optional[float]
            Deprecated

        mmr_lambda : typing.Optional[float]
            weighting for maximal marginal relevance

        reranker : typing.Optional[GraphitiReranker]
            Defaults to RRF

        scope : typing.Optional[GraphitiGraphSearchScope]
            Defaults to Edges. Communities will be added in the future.

        search_filters : typing.Optional[GraphitiSearchFilters]
            Search filters to apply to the search

        user_id : typing.Optional[str]
            The user_id when searching user graph. If not searching user graph, please use graph_id instead.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[ApidataGraphSearchResults]
            Graph search results
        """
        _response = await self._client_wrapper.httpx_client.request(
            "graph/search",
            method="POST",
            json={
                "bfs_origin_node_uuids": bfs_origin_node_uuids,
                "center_node_uuid": center_node_uuid,
                "graph_id": graph_id,
                "limit": limit,
                "min_fact_rating": min_fact_rating,
                "min_score": min_score,
                "mmr_lambda": mmr_lambda,
                "query": query,
                "reranker": reranker,
                "scope": scope,
                "search_filters": convert_and_respect_annotation_metadata(
                    object_=search_filters, annotation=GraphitiSearchFilters, direction="write"
                ),
                "user_id": user_id,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ApidataGraphSearchResults,
                    parse_obj_as(
                        type_=ApidataGraphSearchResults,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 400:
                raise BadRequestError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def create(
        self,
        *,
        graph_id: str,
        description: typing.Optional[str] = OMIT,
        fact_rating_instruction: typing.Optional[ApidataFactRatingInstruction] = OMIT,
        name: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncHttpResponse[ApidataGraph]:
        """
        Creates a new graph.

        Parameters
        ----------
        graph_id : str

        description : typing.Optional[str]

        fact_rating_instruction : typing.Optional[ApidataFactRatingInstruction]

        name : typing.Optional[str]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[ApidataGraph]
            The added graph
        """
        _response = await self._client_wrapper.httpx_client.request(
            "graphs",
            method="POST",
            json={
                "description": description,
                "fact_rating_instruction": convert_and_respect_annotation_metadata(
                    object_=fact_rating_instruction, annotation=ApidataFactRatingInstruction, direction="write"
                ),
                "graph_id": graph_id,
                "name": name,
            },
            headers={
                "content-type": "application/json",
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ApidataGraph,
                    parse_obj_as(
                        type_=ApidataGraph,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 400:
                raise BadRequestError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def get(
        self, graph_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[ApidataGraph]:
        """
        Returns a graph.

        Parameters
        ----------
        graph_id : str
            The graph_id of the graph to get.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[ApidataGraph]
            The graph that was retrieved.
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"graphs/{jsonable_encoder(graph_id)}",
            method="GET",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ApidataGraph,
                    parse_obj_as(
                        type_=ApidataGraph,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 404:
                raise NotFoundError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)

    async def delete(
        self, graph_id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> AsyncHttpResponse[ApidataSuccessResponse]:
        """
        Deletes a graph. If you would like to delete a user graph, make sure to use user.delete instead.

        Parameters
        ----------
        graph_id : str
            Graph ID

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncHttpResponse[ApidataSuccessResponse]
            Deleted
        """
        _response = await self._client_wrapper.httpx_client.request(
            f"graphs/{jsonable_encoder(graph_id)}",
            method="DELETE",
            request_options=request_options,
        )
        try:
            if 200 <= _response.status_code < 300:
                _data = typing.cast(
                    ApidataSuccessResponse,
                    parse_obj_as(
                        type_=ApidataSuccessResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
                return AsyncHttpResponse(response=_response, data=_data)
            if _response.status_code == 400:
                raise BadRequestError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            if _response.status_code == 404:
                raise NotFoundError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    headers=dict(_response.headers),
                    body=typing.cast(
                        ApidataApiError,
                        parse_obj_as(
                            type_=ApidataApiError,  # type: ignore
                            object_=_response.json(),
                        ),
                    ),
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response.text)
        raise ApiError(status_code=_response.status_code, headers=dict(_response.headers), body=_response_json)
